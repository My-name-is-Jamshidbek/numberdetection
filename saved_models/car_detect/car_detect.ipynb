{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T16:09:15.104857563Z",
     "start_time": "2024-02-08T16:09:10.861573785Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:09:11.380549: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# from utils import label_map_util\n",
    "from PIL import Image\n",
    "import uuid\n",
    "\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T16:09:15.128252171Z",
     "start_time": "2024-02-08T16:09:15.107505675Z"
    }
   },
   "outputs": [],
   "source": [
    "#Path to saved model  \n",
    "\n",
    "PATH_TO_SAVED_MODEL = \"/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/saved_models/car_detect/saved_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T16:10:00.840369009Z",
     "start_time": "2024-02-08T16:09:15.126179592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:09:17.198929: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "print(\"Loading saved model ...\")\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "print(\"Model Loaded!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T16:10:00.842452077Z",
     "start_time": "2024-02-08T16:10:00.832130192Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualise_on_image(image, bboxes, labels, scores, thresh):\n",
    "    (h, w, d) = image.shape\n",
    "    for bbox, label, score in zip(bboxes, labels, scores):\n",
    "        if score > thresh:\n",
    "            xmin, ymin = int(bbox[1]*w), int(bbox[0]*h)\n",
    "            xmax, ymax = int(bbox[3]*w), int(bbox[2]*h)\n",
    "            cv2.imwrite(\"/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/cars/\"+str(uuid.uuid4()) + '.jpg', frame)\n",
    "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0,255,0), 2)\n",
    "            cv2.putText(image, f\"{label}: {int(score*100)} %\", (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m frame_name \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39mlistdir(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/gate/photos_day_1/photos\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m      3\u001B[0m     frame \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/gate/photos_day_1/photos/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mframe_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m     old_frame \u001B[38;5;241m=\u001B[39m \u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m()\n\u001B[1;32m      6\u001B[0m     image_np \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mcvtColor(frame, cv2\u001B[38;5;241m.\u001B[39mCOLOR_BGR2RGB)\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\u001B[39;00m\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;66;03m# The model expects a batch of images, so also add an axis with `tf.newaxis`.\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "for frame_name in os.listdir(\"/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/gate/photos_day_1/photos\"):\n",
    "    \n",
    "    frame = cv2.imread(f\"/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/gate/photos_day_1/photos/{frame_name}\")\n",
    "    old_frame = frame.copy()\n",
    "\n",
    "    image_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    # The model expects a batch of images, so also add an axis with `tf.newaxis`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]\n",
    "\n",
    "    # Pass frame through detector\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # Set detection parameters\n",
    "\n",
    "    score_thresh = 0.4   # Minimum threshold for object detection\n",
    "    max_detections = 1\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    scores = detections['detection_scores'][0, :max_detections].numpy()\n",
    "    bboxes = detections['detection_boxes'][0, :max_detections].numpy()\n",
    "    labels = detections['detection_classes'][0, :max_detections].numpy().astype(np.int64)\n",
    "    # labels = [category_index[n]['name'] for n in labels]\n",
    "\n",
    "    # Display detections\n",
    "    visualise_on_image(frame, bboxes, labels, scores, score_thresh)\n",
    "    # height, width, _ = frame.shape\n",
    "\n",
    "    # Calculate new dimensions (50% of original)\n",
    "    # new_width = int(width * 0.5)\n",
    "    # new_height = int(height * 0.5)\n",
    "\n",
    "    # Resize the frame to 50% width and height\n",
    "    # resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "    # cv2.imshow('Video', resized_frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T17:21:28.180754400Z",
     "start_time": "2024-02-08T16:20:12.383078188Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for frame_name in os.listdir(\"/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/gate/photos_day_1/photos (copy 1)\"):\n",
    "    \n",
    "    frame = cv2.imread(f\"/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/gate/photos_day_1/photos (copy 1)/{frame_name}\")\n",
    "    old_frame = frame.copy()\n",
    "\n",
    "    image_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    # The model expects a batch of images, so also add an axis with `tf.newaxis`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]\n",
    "\n",
    "    # Pass frame through detector\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # Set detection parameters\n",
    "\n",
    "    score_thresh = 0.4   # Minimum threshold for object detection\n",
    "    max_detections = 1\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    scores = detections['detection_scores'][0, :max_detections].numpy()\n",
    "    bboxes = detections['detection_boxes'][0, :max_detections].numpy()\n",
    "    labels = detections['detection_classes'][0, :max_detections].numpy().astype(np.int64)\n",
    "    # labels = [category_index[n]['name'] for n in labels]\n",
    "\n",
    "    # Display detections\n",
    "    visualise_on_image(frame, bboxes, labels, scores, score_thresh)\n",
    "    # height, width, _ = frame.shape\n",
    "\n",
    "    # Calculate new dimensions (50% of original)\n",
    "    # new_width = int(width * 0.5)\n",
    "    # new_height = int(height * 0.5)\n",
    "\n",
    "    # Resize the frame to 50% width and height\n",
    "    # resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "    # cv2.imshow('Video', resized_frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T17:21:28.194135222Z",
     "start_time": "2024-02-08T17:21:28.187962988Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for frame_name in os.listdir(\"/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/gate/photos_day_2/1\"):\n",
    "    \n",
    "    frame = cv2.imread(f\"/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/gate/photos_day_2/1/{frame_name}\")\n",
    "    old_frame = frame.copy()\n",
    "\n",
    "    image_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    # The model expects a batch of images, so also add an axis with `tf.newaxis`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]\n",
    "\n",
    "    # Pass frame through detector\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # Set detection parameters\n",
    "\n",
    "    score_thresh = 0.4   # Minimum threshold for object detection\n",
    "    max_detections = 1\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    scores = detections['detection_scores'][0, :max_detections].numpy()\n",
    "    bboxes = detections['detection_boxes'][0, :max_detections].numpy()\n",
    "    labels = detections['detection_classes'][0, :max_detections].numpy().astype(np.int64)\n",
    "    # labels = [category_index[n]['name'] for n in labels]\n",
    "\n",
    "    # Display detections\n",
    "    visualise_on_image(frame, bboxes, labels, scores, score_thresh)\n",
    "    # height, width, _ = frame.shape\n",
    "\n",
    "    # Calculate new dimensions (50% of original)\n",
    "    # new_width = int(width * 0.5)\n",
    "    # new_height = int(height * 0.5)\n",
    "\n",
    "    # Resize the frame to 50% width and height\n",
    "    # resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "    # cv2.imshow('Video', resized_frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T17:21:28.196895676Z",
     "start_time": "2024-02-08T17:21:28.194141678Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for frame_name in os.listdir(\"/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/gate/photos_day_2/2\"):\n",
    "    \n",
    "    frame = cv2.imread(f\"/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/gate/photos_day_2/2/{frame_name}\")\n",
    "    old_frame = frame.copy()\n",
    "\n",
    "    image_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    # The model expects a batch of images, so also add an axis with `tf.newaxis`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]\n",
    "\n",
    "    # Pass frame through detector\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # Set detection parameters\n",
    "\n",
    "    score_thresh = 0.4   # Minimum threshold for object detection\n",
    "    max_detections = 1\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    scores = detections['detection_scores'][0, :max_detections].numpy()\n",
    "    bboxes = detections['detection_boxes'][0, :max_detections].numpy()\n",
    "    labels = detections['detection_classes'][0, :max_detections].numpy().astype(np.int64)\n",
    "    # labels = [category_index[n]['name'] for n in labels]\n",
    "\n",
    "    # Display detections\n",
    "    visualise_on_image(frame, bboxes, labels, scores, score_thresh)\n",
    "    # height, width, _ = frame.shape\n",
    "\n",
    "    # Calculate new dimensions (50% of original)\n",
    "    # new_width = int(width * 0.5)\n",
    "    # new_height = int(height * 0.5)\n",
    "\n",
    "    # Resize the frame to 50% width and height\n",
    "    # resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "    # cv2.imshow('Video', resized_frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-08T17:21:28.202190590Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for frame_name in os.listdir(\"/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/gate/photos_day_2/3\"):\n",
    "    \n",
    "    frame = cv2.imread(f\"/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/gate/photos_day_2/3/{frame_name}\")\n",
    "    old_frame = frame.copy()\n",
    "\n",
    "    image_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    # The model expects a batch of images, so also add an axis with `tf.newaxis`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]\n",
    "\n",
    "    # Pass frame through detector\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # Set detection parameters\n",
    "\n",
    "    score_thresh = 0.4   # Minimum threshold for object detection\n",
    "    max_detections = 1\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    scores = detections['detection_scores'][0, :max_detections].numpy()\n",
    "    bboxes = detections['detection_boxes'][0, :max_detections].numpy()\n",
    "    labels = detections['detection_classes'][0, :max_detections].numpy().astype(np.int64)\n",
    "    # labels = [category_index[n]['name'] for n in labels]\n",
    "\n",
    "    # Display detections\n",
    "    visualise_on_image(frame, bboxes, labels, scores, score_thresh)\n",
    "    # height, width, _ = frame.shape\n",
    "\n",
    "    # Calculate new dimensions (50% of original)\n",
    "    # new_width = int(width * 0.5)\n",
    "    # new_height = int(height * 0.5)\n",
    "\n",
    "    # Resize the frame to 50% width and height\n",
    "    # resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "    # cv2.imshow('Video', resized_frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T17:21:28.261801117Z",
     "start_time": "2024-02-08T17:21:28.208434728Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for frame_name in os.listdir(\"/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/gate/photos_day_3/1\"):\n",
    "    \n",
    "    frame = cv2.imread(f\"/media/kkr/Files/ukgkhb/ai/ready_models/number_detection/gate/photos_day_3/1/{frame_name}\")\n",
    "    old_frame = frame.copy()\n",
    "\n",
    "    image_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    # The model expects a batch of images, so also add an axis with `tf.newaxis`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]\n",
    "\n",
    "    # Pass frame through detector\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # Set detection parameters\n",
    "\n",
    "    score_thresh = 0.4   # Minimum threshold for object detection\n",
    "    max_detections = 1\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    scores = detections['detection_scores'][0, :max_detections].numpy()\n",
    "    bboxes = detections['detection_boxes'][0, :max_detections].numpy()\n",
    "    labels = detections['detection_classes'][0, :max_detections].numpy().astype(np.int64)\n",
    "    # labels = [category_index[n]['name'] for n in labels]\n",
    "\n",
    "    # Display detections\n",
    "    visualise_on_image(frame, bboxes, labels, scores, score_thresh)\n",
    "    # height, width, _ = frame.shape\n",
    "\n",
    "    # Calculate new dimensions (50% of original)\n",
    "    # new_width = int(width * 0.5)\n",
    "    # new_height = int(height * 0.5)\n",
    "\n",
    "    # Resize the frame to 50% width and height\n",
    "    # resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "    # cv2.imshow('Video', resized_frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-08T17:21:28.212635856Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T09:21:55.043108195Z",
     "start_time": "2024-02-08T09:21:54.995058037Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Video Capture (video_file)\n",
    "video_capture = cv2.VideoCapture(\"/home/kkr/Videos/ai/ready_models/car_detect/recource/20230817_181414.mp4\")\n",
    "start_time = time.time()\n",
    "\n",
    "frame_width = int(video_capture.get(3))\n",
    "frame_height = int(video_capture.get(4))\n",
    "#fps = int(video_capture.get(5))\n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "#Initialize video writer\n",
    "# result = cv2.VideoWriter('/mydrive/result.avi', cv2.VideoWriter_fourcc(*'MJPG'),15, size)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        print('Unable to read video / Video ended')\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    image_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    # The model expects a batch of images, so also add an axis with `tf.newaxis`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]\n",
    "\n",
    "    # Pass frame through detector\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # Set detection parameters\n",
    "\n",
    "    score_thresh = 0.4   # Minimum threshold for object detection\n",
    "    max_detections = 1\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    scores = detections['detection_scores'][0, :max_detections].numpy()\n",
    "    bboxes = detections['detection_boxes'][0, :max_detections].numpy()\n",
    "    labels = detections['detection_classes'][0, :max_detections].numpy().astype(np.int64)\n",
    "    # labels = [category_index[n]['name'] for n in labels]\n",
    "\n",
    "    # Display detections\n",
    "    visualise_on_image(frame, bboxes, labels, scores, score_thresh)\n",
    "\n",
    "    end_time = time.time()\n",
    "    fps = int(1/(end_time - start_time))\n",
    "    start_time = end_time\n",
    "    cv2.putText(frame, f\"FPS: {fps}\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 1)\n",
    "    # cv2_imshow(frame)\n",
    "    \n",
    "    # Write output video\n",
    "    # result.write(frame)\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
